# -*- coding: utf-8 -*-
"""train_reward_model_v2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hPZQxn2_eiQCEJsMn_qfeP0tzAA94KF8

# Setting
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
from tqdm.auto import tqdm
from torch.utils.data import random_split, Dataset, DataLoader
import os
from PIL import Image
import torchvision.transforms as transforms
import numpy as np
import torchvision.models as models
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

"""# Dataset"""

!cp /content/drive/MyDrive/cv프로젝트/celeba_dataset.zip /content/
!unzip -q /content/celeba_dataset.zip -d /content/real/

!cp /content/drive/MyDrive/cv프로젝트/DDIM_3000.zip /content/
!unzip -q /content/DDIM_3000.zip -d /content/fake/

class DeepfakeDataset(Dataset):
    def __init__(self, real_img_dir, fake_img_dir, num_noise=500, transform=None):
        self.real_img_dir = real_img_dir
        self.fake_img_dir = fake_img_dir
        self.real_img_list = os.listdir(real_img_dir)[:3000+num_noise]
        self.fake_img_list = os.listdir(fake_img_dir)
        if len(self.fake_img_list)!=3000:
            raise Exception("Number of fake images is not 3000")

        self.num_real_img = 3000 + num_noise
        self.num_fake_img = 3000 + num_noise
        self.num_noise = num_noise // 2
        self.num_white = num_noise // 4
        self.num_black = num_noise // 4

        self.transform = transform

    def __len__(self):
        return self.num_real_img + self.num_fake_img

    def _make_random_noise_pil(self):
        # gaussian around 0.5 with std 0.2 clipped to [0,1]
        arr = np.random.normal(loc=0.5, scale=0.2, size=(64,64,3))
        arr = np.clip(arr, 0.0, 1.0)
        arr = (arr * 255.0).astype(np.uint8)
        return Image.fromarray(arr)

    def _make_white_pil(self):
        return Image.new('RGB', (64,64), (255, 255, 255))

    def _make_black_pil(self):
        return Image.new('RGB', (64,64), (0, 0, 0))

    def __getitem__(self, idx):
        if idx < self.num_real_img:
            img_path = os.path.join(self.real_img_dir, self.real_img_list[idx])
            img = Image.open(img_path).convert('RGB')
            label = 1 # real
        elif idx<self.num_real_img + 3000:
            img_path = os.path.join(self.fake_img_dir, self.fake_img_list[idx - self.num_real_img])
            img = Image.open(img_path).convert('RGB')
            label = 0 # fake
        else:
            if idx < self.num_real_img + 3000 + self.num_noise:
                img = self._make_random_noise_pil()
            elif idx < self.num_real_img + 3000 + self.num_noise + self.num_white:
                img = self._make_white_pil()
            else:
                img = self._make_black_pil()
            label = 0

        if self.transform:
            img = self.transform(img)

        return img, label

transform = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

dataset = DeepfakeDataset(real_img_dir='/content/real/img_align_celeba', fake_img_dir='/content/fake/DDIM_3000', num_noise=500, transform=transform)

ratio = 0.1
train_dataset, test_dataset = random_split(dataset, [int((1-ratio)*len(dataset)), int(ratio*len(dataset))])
print(len(train_dataset), len(test_dataset))

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)

"""# Model"""

class ConvBlock(nn.Module):
    def __init__(self, in_c, out_c, kernel=3, stride=1, padding=1, pool=True):
        super().__init__()
        self.conv = nn.Conv2d(in_c, out_c, kernel, stride, padding, bias=False)
        self.bn = nn.BatchNorm2d(out_c)
        self.act = nn.GELU()
        self.pool = nn.AvgPool2d(2) if pool else nn.Identity()

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.act(x)
        x = self.pool(x)
        return x

class SimpleRewardModel(nn.Module):
    # Simple reward model used in PPO finetuning.
    def __init__(self, in_channels=3, base_channels=32, dropout=0.2):
        super().__init__()
        b = base_channels
        self.blocks = nn.Sequential(
            ConvBlock(in_channels, b, pool=True),
            ConvBlock(b, b*2, pool=True),
            ConvBlock(b*2, b*4, pool=True),
            ConvBlock(b*4, b*8, pool=True),
        )
        self.head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(dropout),
            nn.Linear(b*8, 128),
            nn.GELU(),
            nn.Linear(128, 1)
        )
        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
            elif isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)

    def forward(self, x):
        x = self.blocks(x)
        x = self.head(x)
        return x.view(-1)

"""# Train"""

device = 'cuda' if torch.cuda.is_available() else 'cpu'
rm = SimpleRewardModel().to(device)
optimizer = torch.optim.Adam(rm.parameters(), lr=1e-4)
label_smoothing = 0.05

rm.train()
loss_fn = nn.BCEWithLogitsLoss()

for epoch in range(10):
    loss_sum = 0.0
    for imgs, labels in train_loader:
        imgs = imgs.to(device)
        labels = labels.float().to(device)
        labels = labels * (1.0 - label_smoothing) + 0.5 * label_smoothing
        logits = rm(imgs)
        loss = loss_fn(logits, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        loss_sum += loss.item()

    rm.eval()
    count = 0
    total = 0
    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs = imgs.to(device)
            labels = labels.to(device).long()
            logits = rm(imgs)
            preds = (torch.sigmoid(logits) > 0.5).long()
            count += (preds == labels).sum().item()
            total += labels.size(0)
    acc = count / total

    print(f'epoch {epoch+1} loss: {loss_sum/len(train_loader):.4f} acc: {acc:.4f}')

torch.save(rm.state_dict(), '/content/drive/MyDrive/논문코드리뷰/논문코드리뷰_PPO/reward_model_v2.pt')